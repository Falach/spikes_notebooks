{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scalp_utils_fif import *\n",
    "import joblib\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from scipy import stats\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AO0', 'DH3', 'MF7', 'MM1', 'SS1', 'TA1', 'YS5']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the path to the folder containing the data. folder should contain two subfolders: HC and EPI\n",
    "folder = r\"D:\\EPI_MFF\\NREM_EOG_AVE_XGB\"\n",
    "egi_nrem_path_HC = folder +\"\\HC\\%s.fif\"\n",
    "egi_nrem_path_EPI = folder +\"\\EPI\\%s.fif\"\n",
    "subjects_HC = [os.path.splitext(x)[0] for x in os.listdir(folder +\"\\HC\")]\n",
    "subjects_EPI = [os.path.splitext(x)[0] for x in os.listdir(folder +\"\\EPI\")]\n",
    "\n",
    "subjects_EPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load all models\n",
    "rf_model = joblib.load('rf_under_19.pkl')\n",
    "rf_model_Balanced = joblib.load('rf_full_balanced_19.pkl')\n",
    "rf_model_1_10 = joblib.load('rf_full_1_10_ratio_19.pkl')\n",
    "lgbm_model = joblib.load('lgbm_under_19.pkl')\n",
    "lgbm_model_Balanced = joblib.load('lgbm_full_balanced_19.pkl')\n",
    "lgbm_model_1_10 = joblib.load('lgbm_full_1_10_ratio_19.pkl')\n",
    "lgbm_model_origin = joblib.load('lgbm_full_origin_19.pkl')\n",
    "xgb = joblib.load('xgb_full_origin_19.pkl')\n",
    "xgb_Balanced = joblib.load('xgb_full_balanced_19.pkl')\n",
    "xgb_1_10 = joblib.load('xgb_full_1_10_ratio_19.pkl')\n",
    "lgbm_model_origin_70 = joblib.load('lgbm_full_origin_70_19.pkl')\n",
    "lgbm_origin_symmetric = joblib.load('lgbm_full_origin_symmetric_19.pkl')\n",
    "xgb_origin_Balanced_70 = joblib.load('xgb_full_balanced_70_19.pkl')\n",
    "xgb_model_1_10_70 = joblib.load('xgb_full_1_10_ratio_70_19.pkl')\n",
    "xgb_model_1_10_fixed = joblib.load('xgb_full_1_10_ratio_19_fix_prob.pkl')\n",
    "xgb_model_fixed = joblib.load('xgb_full_origin_19_fix_prob.pkl')\n",
    "xgb__balanced_symmetric = joblib.load('xgb_full_balanced_symmetric_19.pkl')\n",
    "xgb_symmetric = joblib.load('xgb_full_origin_symmetric_19.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model amd electrodes to use\n",
    "model = xgb_model_fixed\n",
    "el1 = 'E219'\n",
    "el2 = 'E241'\n",
    "# predict proba for all subjects, each subject is saved in a variable with his id\n",
    "\n",
    "\n",
    "model_name = str(model)[:str(model).find('(')]\n",
    "eog1_dict = {}\n",
    "eog2_dict = {}\n",
    "for subj in subjects_HC:\n",
    "    feat_eog1 = get_all_feat_eog_with_chan_feat(el1, subjects=[subj], path=egi_nrem_path_HC)\n",
    "    clear_output()\n",
    "    eog1_dict[subj] = feat_eog1\n",
    "    feat_eog2 = get_all_feat_eog_with_chan_feat(el2, subjects=[subj], path=egi_nrem_path_HC)\n",
    "    clear_output()\n",
    "    eog2_dict[subj] = feat_eog2\n",
    "    # E1-LM\n",
    "   \n",
    "\n",
    "joblib.dump(eog1_dict, f'eog1_egi.pkl')\n",
    "joblib.dump(eog2_dict, f'eog2_egi.pkl')\n",
    "eog1_dict = joblib.load('eog1_egi.pkl')\n",
    "eog2_dict = joblib.load('eog2_egi.pkl')\n",
    "feat_all = pd.DataFrame()\n",
    "for subj in subjects_HC:\n",
    "    curr_feat = pd.concat([eog1_dict[subj].iloc[:, 2:], eog2_dict[subj].iloc[:, 2:].add_suffix('_2')], axis=1)\n",
    "    \n",
    "    for classifier in [model]:\n",
    "        # save classifier.predict_proba(curr_feat) in variable with name subj\n",
    "        vars()[subj] = classifier.predict_proba(curr_feat)\n",
    "        vars()[subj+'_pred'] = classifier.predict(curr_feat)\n",
    "        \n",
    "        print(subj)\n",
    "eog1_dict = {}\n",
    "eog2_dict = {}\n",
    "for subj in subjects_EPI:\n",
    "    feat_eog1 = get_all_feat_eog_with_chan_feat(el1, subjects=[subj], path=egi_nrem_path_EPI)\n",
    "    clear_output()\n",
    "    eog1_dict[subj] = feat_eog1\n",
    "    feat_eog2 = get_all_feat_eog_with_chan_feat(el2, subjects=[subj], path=egi_nrem_path_EPI)\n",
    "    clear_output()\n",
    "    eog2_dict[subj] = feat_eog2\n",
    "\n",
    "joblib.dump(eog1_dict, f'eog1_egi.pkl')\n",
    "joblib.dump(eog2_dict, f'eog2_egi.pkl')\n",
    "eog1_dict = joblib.load('eog1_egi.pkl')\n",
    "eog2_dict = joblib.load('eog2_egi.pkl')\n",
    "feat_all = pd.DataFrame()\n",
    "for subj in subjects_EPI:\n",
    "    curr_feat = pd.concat([eog1_dict[subj].iloc[:, 2:], eog2_dict[subj].iloc[:, 2:].add_suffix('_2')], axis=1)\n",
    "    \n",
    "    for classifier in [model]:\n",
    "        # save classifier.predict_proba(curr_feat) in variable with name subj\n",
    "        vars()[subj] = classifier.predict_proba(curr_feat)\n",
    "        vars()[subj+'_pred'] = classifier.predict(curr_feat)\n",
    "        \n",
    "        print(subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "sample_raw = mne.io.read_raw_fif(r\"C:\\Users\\mad17\\Desktop\\VE\\MFF\\AO0.fif\", preload=False, verbose=False)\n",
    "plt.rcParams['figure.figsize'] = [2, 2]\n",
    "sensors = plt.figure()\n",
    "sample_raw.plot_sensors(ch_type=\"eeg\" ,ch_groups=[[sample_raw.info['ch_names'].index(el1)],[sample_raw.info['ch_names'].index(el2)]])\n",
    "tests = pd.DataFrame(columns=['threshols', 't-test', 'p-value', 'mann-whitney', 'p-value'])\n",
    "colors = ['#ff355e', '#fd5b78', '#ff6037', '#ff9966', '#ff9933', '#ffcc33', '#ffff66', '#ccff00', '#66ff66', '#50bfe6', '#aaf0d1', '#16d0cb', '#9c27b0', '#ee34d2', '#ff00cc']\t\n",
    "fig, axs = plt.subplots(1, 7, figsize=(20, 6))\n",
    "for i, threshold in enumerate([0.5,0.6, 0.7, 0.8, 0.85, 0.9, 0.95]):\n",
    "    df = pd.DataFrame(columns=['subject', 'Spikes_per_min', 'group'])\n",
    "    # Check threshold for each subject, if prediction is above threshold, it is considered as spike\n",
    "    for subj in subjects_HC:\n",
    "        vars()[subj + 'Tr'] = [0 if i < threshold else 1 for i in vars()[subj][:, 0]]\n",
    "        \n",
    "    for subj in subjects_EPI:\n",
    "        vars()[subj + 'Tr'] = [0 if i < threshold else 1 for i in vars()[subj][:, 0]]\n",
    "    #Sum all spikes for each subject and divide by the number of minutes in the recording to get spikes per minute\n",
    "    for subj in subjects_HC:\n",
    "        \n",
    "        vars()[subj + 'Tr'] = np.sum(vars()[subj+ 'Tr'])/(len(vars()[subj+ 'Tr'])/240)\n",
    "    for subj in subjects_EPI:\n",
    "        vars()[subj + 'Tr'] = np.sum(vars()[subj+ 'Tr'])/(len(vars()[subj+ 'Tr'])/240)\n",
    "\n",
    "\n",
    "    # create df \n",
    "    df = pd.DataFrame(columns=['subject', 'Spikes_per_min', 'group'])\n",
    "\n",
    "     \n",
    "    for subj in subjects_HC:\n",
    "        df.loc[len(df)] = [subj, vars()[subj+ 'Tr'], 'HC']\n",
    "    for subj in subjects_EPI:\n",
    "        df.loc[len(df)] = [subj, vars()[subj+ 'Tr'], 'EPI']\n",
    "    # perform t test, mann whitney u test between EPI and HC\n",
    "    tests.loc[len(tests)] = [threshold, ttest_ind(df[df.group == 'HC'].Spikes_per_min, df[df.group == 'EPI'].Spikes_per_min)[0], ttest_ind(df[df.group == 'HC'].Spikes_per_min, df[df.group == 'EPI'].Spikes_per_min)[1], mannwhitneyu(df[df.group == 'HC'].Spikes_per_min, df[df.group == 'EPI'].Spikes_per_min)[0], mannwhitneyu(df[df.group == 'HC'].Spikes_per_min, df[df.group == 'EPI'].Spikes_per_min)[1]]\n",
    "    # add colors to df\n",
    "    df['color'] = colors\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "    sns.boxplot(x='group', y='Spikes_per_min', data=df, ax=axs[i],color='white', width=0.5, fliersize=0)\n",
    "    for j, subj in enumerate(subjects_HC):\n",
    "        axs[i].scatter(0, vars()[subj+ 'Tr'], color=df[df.subject == subj].color.values[0])\n",
    "        \n",
    "    \n",
    "    # set title for each subplot with t-test and mann whitney u test\n",
    "    axs[i].set_title(f'{threshold} \\n T: {round(tests[tests.threshols == threshold].iloc[0, 1], 2)}, MW: {round(tests[tests.threshols == threshold].iloc[0, 3], 2)}')\n",
    "    \n",
    "     \n",
    "#   cycle for EPI subjects to add dot for each subject with different color from colors list\n",
    "    for j, subj in enumerate(subjects_EPI):\n",
    "        axs[i].scatter(1, vars()[subj+ 'Tr'], color=df[df.subject == subj].color.values[0])\n",
    "        # add legend with colors and subject names\n",
    "        \n",
    "#   legend with colors and subject names according to df[colors]\n",
    "    legend_elements = [mpatches.Patch(color=df[df.subject == subj].color.values[0], label=subj) for subj in subjects_HC] + [mpatches.Patch(color=df[df.subject == subj].color.values[0], label=subj) for subj in subjects_EPI]\n",
    "    \n",
    "    # show it 1 time\n",
    "    if i == 0:\n",
    "            axs[i].legend(handles=legend_elements, bbox_to_anchor = (8.69, 1), fontsize=8)\n",
    "    \n",
    "\n",
    "    # set 1 title for the whole figure with model name, threshold range, and el1, el2 names\n",
    "    fig.suptitle(f'{model_name} 0.3-40,  {el1}  {el2}')\n",
    "    \n",
    "\n",
    "for ax in axs:\n",
    "    ax.set(xlabel='')\n",
    "\n",
    "for ax in axs[1:]:\n",
    "    ax.set(ylabel='')\n",
    "\n",
    "\n",
    "\n",
    "# # save figure\n",
    "# plt.savefig('LGBM.03_E2.png')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all combination of sensors by performing t-test abd MW test ot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approx takes 24 hours to run with 47 sensors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "# pick on of the files to get sensors list\n",
    "sensors_raw = mne.io.read_raw_fif(r\"D:\\EPI_MFF\\NREM_EOG_DB\\HC\\EB34.fif\", preload=False, verbose=False)\n",
    "sensors_raw.info['ch_names']\n",
    "tests_m = pd.DataFrame(columns=['sensor1','sensor2','threshold', 't-test', 'T_p-value', 'mann-whitney', 'MU_p-value'])\n",
    "# choose model\n",
    "model = rf_model_Balanced\n",
    "\n",
    "sensors = sensors_raw.info['ch_names']\n",
    "# cycle through all combination of 2 sensors with printing all combinations\n",
    "for i in range(len(sensors)):\n",
    "    for j in range(i+1, len(sensors)):\n",
    "        print(sensors[i], sensors[j])\n",
    "       \n",
    "        eog1_dict = {}\n",
    "        eog2_dict = {}\n",
    "        for subj in subjects_HC:\n",
    "            feat_eog1 = get_all_feat_eog_with_chan_feat(sensors[i], subjects=[subj], path=egi_nrem_path_HC)\n",
    "            clear_output()\n",
    "            eog1_dict[subj] = feat_eog1\n",
    "            feat_eog2 = get_all_feat_eog_with_chan_feat(sensors[j], subjects=[subj], path=egi_nrem_path_HC)\n",
    "            clear_output()\n",
    "            eog2_dict[subj] = feat_eog2\n",
    "\n",
    "\n",
    "        joblib.dump(eog1_dict, f'eog1_egi.pkl')\n",
    "        joblib.dump(eog2_dict, f'eog2_egi.pkl')\n",
    "        eog1_dict = joblib.load('eog1_egi.pkl')\n",
    "        eog2_dict = joblib.load('eog2_egi.pkl')\n",
    "        feat_all = pd.DataFrame()\n",
    "        for subj in subjects_HC:\n",
    "            curr_feat = pd.concat([eog1_dict[subj].iloc[:, 2:], eog2_dict[subj].iloc[:, 2:].add_suffix('_2')], axis=1)\n",
    "            \n",
    "            for classifier in [model]:\n",
    "                \n",
    "                vars()[subj] = classifier.predict_proba(curr_feat)\n",
    "              \n",
    "                print(subj)\n",
    "        eog1_dict = {}\n",
    "        eog2_dict = {}\n",
    "        for subj in subjects_EPI:\n",
    "            feat_eog1 = get_all_feat_eog_with_chan_feat(sensors[i], subjects=[subj], path=egi_nrem_path_EPI)\n",
    "            clear_output()\n",
    "            eog1_dict[subj] = feat_eog1\n",
    "            feat_eog2 = get_all_feat_eog_with_chan_feat(sensors[j], subjects=[subj], path=egi_nrem_path_EPI)\n",
    "            clear_output()\n",
    "            eog2_dict[subj] = feat_eog2\n",
    "\n",
    "        joblib.dump(eog1_dict, f'eog1_egi.pkl')\n",
    "        joblib.dump(eog2_dict, f'eog2_egi.pkl')\n",
    "        eog1_dict = joblib.load('eog1_egi.pkl')\n",
    "        eog2_dict = joblib.load('eog2_egi.pkl')\n",
    "        feat_all = pd.DataFrame()\n",
    "        for subj in subjects_EPI:\n",
    "            curr_feat = pd.concat([eog1_dict[subj].iloc[:, 2:], eog2_dict[subj].iloc[:, 2:].add_suffix('_2')], axis=1)\n",
    "            \n",
    "            for classifier in [model]:\n",
    "          \n",
    "               \n",
    "                print(subj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for q, threshold in enumerate([0.5,0.6, 0.7, 0.8, 0.85, 0.9, 0.95]):\n",
    "            df = pd.DataFrame(columns=['subject', 'Spikes_per_min', 'group'])\n",
    "            for subj in subjects_HC:\n",
    "                vars()[subj + 'Tr'] = [0 if q < threshold else 1 for q in vars()[subj][:, 0]]\n",
    "                \n",
    "            for subj in subjects_EPI:\n",
    "                vars()[subj + 'Tr'] = [0 if q < threshold else 1 for q in vars()[subj][:, 0]]\n",
    "\n",
    "            for subj in subjects_HC:\n",
    "                \n",
    "                vars()[subj + 'Tr'] = np.sum(vars()[subj+ 'Tr'])/(len(vars()[subj+ 'Tr'])/240)\n",
    "            for subj in subjects_EPI:\n",
    "                vars()[subj + 'Tr'] = np.sum(vars()[subj+ 'Tr'])/(len(vars()[subj+ 'Tr'])/240)\n",
    "\n",
    "\n",
    "            # create df \n",
    "            df = pd.DataFrame(columns=['subject', 'Spikes_per_min', 'group'])\n",
    "\n",
    "          \n",
    "            for subj in subjects_HC:\n",
    "                df.loc[len(df)] = [subj, vars()[subj+ 'Tr'], 'HC 8 ']\n",
    "            for subj in subjects_EPI:\n",
    "                df.loc[len(df)] = [subj, vars()[subj+ 'Tr'], 'EPI 7']\n",
    "            # perform t test, mann whitney u test between the two groups in df dataframe and add resuts and p-values to tests dataframe in the existing columns\n",
    "            tests_m.loc[len(tests_m)] = [sensors[i],sensors[j], threshold, ttest_ind(df[df.group == 'HC 8 '].Spikes_per_min, df[df.group == 'EPI 7'].Spikes_per_min)[0], ttest_ind(df[df.group == 'HC 8 '].Spikes_per_min, df[df.group == 'EPI 7'].Spikes_per_min)[1], mannwhitneyu(df[df.group == 'HC 8 '].Spikes_per_min, df[df.group == 'EPI 7'].Spikes_per_min)[0], mannwhitneyu(df[df.group == 'HC 8 '].Spikes_per_min, df[df.group == 'EPI 7'].Spikes_per_min)[1]]\n",
    "            print(sensors[i],sensors[j])\n",
    "#Save tests dataframe to csv \n",
    "tests_m.to_csv('tests_m_RF_DB.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

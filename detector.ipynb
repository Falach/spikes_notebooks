{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b4308a",
   "metadata": {},
   "source": [
    "This notebook detect spikes according to the given param, union close spikes and save a csv file with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broke-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from scipy import stats, signal\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "threshold_amp = 5  \n",
    "threshold_grad = 5\n",
    "threshold_env = 5 \n",
    "use_env = True\n",
    "use_amp = True\n",
    "use_grad = True\n",
    "block_size_sec = 10  # filter and find peaks at blocks of X seconds - based on Andrillon et al\n",
    "\n",
    "# the bandpass range is based on Andrillon et al\n",
    "low_pass = 50\n",
    "high_pass = 150\n",
    "\n",
    "# general constants\n",
    "min_distance_sec = 0.1  # minimal distance for 'different' spikes - in miliseconds\n",
    "min_spike_length_sec = 0.004  # a spike is detected if there are points for 5 ms passing the threshold, based on Andrillon et al\n",
    "\n",
    "mne.set_log_level(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twenty-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # edf = '/Users/rotemfalach/Documents/University/lab/EDFs_forRotem/402_for_tag.edf'\n",
    "# mne.set_log_level(False)\n",
    "# save_csv = True\n",
    "# edf = 'C:\\\\Users\\\\user\\\\PycharmProjects\\\\pythonProject\\\\results\\\\402\\\\402_for_tag.edf'\n",
    "# raw = mne.io.read_raw_edf(edf)\n",
    "# sampling_rate = int(raw.info['sfreq'])\n",
    "# # TODO: all channels? only RAH both ref methods?\n",
    "# raw.pick_channels(['RAH1-RAH2'])\n",
    "# # raw.crop(tmin=0, tmax=300)\n",
    "\n",
    "# data = raw.get_data()[0]\n",
    "# plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inside-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markers(data, sampling_rate, spikes_list, index_above_threshold, thresh_type):\n",
    "    max_markers_index = []\n",
    "    max_marker_value = []\n",
    "\n",
    "    # find max markers\n",
    "    #     counter = 1\n",
    "    curr_spike = []\n",
    "    curr_spike_data = [thresh_type, index_above_threshold[0]]\n",
    "    curr_spike.append(index_above_threshold[0])\n",
    "    for j in range(len(index_above_threshold)):\n",
    "        # check that the next index is the same spike\n",
    "        if j + 1 < len(index_above_threshold) and index_above_threshold[j + 1] - index_above_threshold[j] == 1:\n",
    "            curr_spike.append(index_above_threshold[j + 1])\n",
    "        # the current spike finished\n",
    "        else:\n",
    "            # check min spike length\n",
    "            if sampling_rate * min_spike_length_sec <= len(curr_spike):\n",
    "                # check if the peak is positive or negative and append it's value\n",
    "                max_value = data[curr_spike[0]: curr_spike[-1] + 1].max()\n",
    "                min_value = data[curr_spike[0]: curr_spike[-1] + 1].min()\n",
    "                value = max_value if abs(max_value) > abs(min_value) else min_value\n",
    "                \n",
    "                # find the index of the spike's peak\n",
    "                index = np.intersect1d(np.where(data == value)[0], curr_spike)[0]\n",
    "                max_marker_value.append(value)\n",
    "                max_markers_index.append(index)\n",
    "                curr_spike_data.extend((index_above_threshold[j], index, value))\n",
    "                spikes_list.append(curr_spike_data)\n",
    "                \n",
    "            # init data for next spike\n",
    "            if j + 1 < len(index_above_threshold):\n",
    "                curr_spike = []\n",
    "                curr_spike_data = [thresh_type, index_above_threshold[j + 1]]\n",
    "                \n",
    "    return np.array(max_markers_index), np.array(max_marker_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supposed-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(data, sampling_rate, threshold_amp, threshold_grad, threshold_env):\n",
    "    spikes_list = []\n",
    "    points_in_block = block_size_sec * sampling_rate\n",
    "    number_of_blocks = math.floor(len(data) / points_in_block)\n",
    "    max_markers_index_amp, max_markers_index_grad, max_markers_index_env = [], [], []\n",
    "\n",
    "    for i in range(number_of_blocks):\n",
    "        curr_block = data[i * points_in_block: (i + 1) * points_in_block]\n",
    "\n",
    "        # check amplitude threshold\n",
    "        if use_amp or use_amp_env or use_amp_grad:\n",
    "            z_score_amp = stats.zscore(curr_block)\n",
    "            points_above_thresh_amp = z_score_amp[z_score_amp > threshold_amp]\n",
    "            # get indexes from z_score values and add offset of the current block\n",
    "            if len(points_above_thresh_amp) > 0:\n",
    "                index_above_threshold_amp = (z_score_amp > threshold_amp).nonzero()[0] + i * points_in_block\n",
    "                curr_markers_index_amp, curr_markers_value_amp = \\\n",
    "                    get_markers(data, sampling_rate, spikes_list, index_above_threshold_amp, 'amp')\n",
    "                max_markers_index_amp.extend(curr_markers_index_amp)\n",
    "\n",
    "\n",
    "        # check gradient threshold\n",
    "        if use_grad or use_amp_grad:\n",
    "            gradient_diff = np.diff(curr_block)\n",
    "            z_score_grad = stats.zscore(np.insert(gradient_diff, 0, 0))\n",
    "            points_above_thresh_grad = z_score_grad[z_score_grad > threshold_grad]\n",
    "            if len(points_above_thresh_grad) > 0:\n",
    "                index_above_threshold_grad = (z_score_grad > threshold_grad).nonzero()[0] + i * points_in_block\n",
    "                curr_markers_index_grad, curr_marker_value_grad = \\\n",
    "                    get_markers(data, sampling_rate, spikes_list, index_above_threshold_grad, 'grad')\n",
    "                max_markers_index_grad.extend(curr_markers_index_grad)\n",
    "\n",
    "        # check envelope threshold\n",
    "        if use_env or use_amp_env:\n",
    "            filtered_block = mne.filter.filter_data(curr_block, sampling_rate, low_pass, high_pass)\n",
    "            env_block = abs(signal.hilbert(filtered_block))\n",
    "            z_score_env = stats.zscore(env_block)\n",
    "            points_above_thresh_env = z_score_env[z_score_env > threshold_env]\n",
    "            if len(points_above_thresh_env) > 0:\n",
    "                index_above_threshold_env = (z_score_env > threshold_env).nonzero()[0] + i * points_in_block\n",
    "                curr_markers_index_env, curr_marker_value_env = \\\n",
    "                    get_markers(data, sampling_rate, spikes_list, index_above_threshold_env, 'env')\n",
    "                max_markers_index_env.extend(curr_markers_index_env)\n",
    "\n",
    "    return spikes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legendary-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data, alpha=0.8)\n",
    "# plt.scatter(max_markers_index_amp, data[max_markers_index_amp] if len(max_markers_index_amp) > 0 else [], marker='X', color='fuchsia')\n",
    "# plt.scatter(max_markers_index_grad, data[max_markers_index_grad] if len(max_markers_index_grad) > 0 else [], marker='P', color='red')\n",
    "# plt.scatter(max_markers_index_env, data[max_markers_index_env] if len(max_markers_index_env) > 0 else [], marker='o', color='blue', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776730ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union close spikes\n",
    "def union_spikes(spikes_df, sampling_rate):\n",
    "    new_spikes_list = []\n",
    "    flag, any_union = False, False\n",
    "    for i, x in spikes_df.iterrows():\n",
    "        # prevent double unions\n",
    "        for j, y in spikes_df[i + 1:].iterrows():\n",
    "            # check distance between the peaks\n",
    "            if abs(x['max_index'] - y['max_index']) / sampling_rate < min_distance_sec:\n",
    "                # more than one union with the current spike x\n",
    "                if flag:\n",
    "                    thresh_type = list(set(curr_union[0] + [y['threshold_type']]))\n",
    "                    max_index, max_amp = (curr_union[3], curr_union[4]) if abs(curr_union[4]) > abs(y['max_amp']) \\\n",
    "                        else (y['max_index'], y['max_amp'])\n",
    "                    curr_union = [thresh_type, min(curr_union[1], y['first_index']), max(curr_union[2], y['last_index']),\n",
    "                         max_index, max_amp]\n",
    "                else:\n",
    "                    thresh_type = list(set([x['threshold_type'], y['threshold_type']]))\n",
    "                    max_index, max_amp = (x['max_index'], x['max_amp']) if abs(x['max_amp']) > abs(y['max_amp']) \\\n",
    "                            else (y['max_index'], y['max_amp'])\n",
    "                    curr_union = [thresh_type, min(x['first_index'], y['first_index']), max(x['last_index'], y['last_index']),\n",
    "                         max_index, max_amp]\n",
    "                flag, any_union = True, True\n",
    "        if flag:\n",
    "            new_spikes_list.append(curr_union)\n",
    "            flag = False\n",
    "        else:\n",
    "            new_spikes_list.append(x.tolist())\n",
    "\n",
    "    columns = ['threshold_type', 'first_index', 'last_index', 'max_index', 'max_amp']\n",
    "    new_spikes_df = pd.DataFrame(new_spikes_list, columns=columns)\n",
    "    new_spikes_df = new_spikes_df.drop_duplicates(subset='max_index')\n",
    "    new_spikes_df['duration'] = new_spikes_df['last_index'] - new_spikes_df['first_index']\n",
    "    new_spikes_df['duration_sec'] = (new_spikes_df['last_index'] - new_spikes_df['first_index']) / sampling_rate\n",
    "    new_spikes_df = new_spikes_df.loc[new_spikes_df['duration_sec'] >= min_spike_length_sec]\n",
    "    # reindex from 1\n",
    "    new_spikes_df.index = np.arange(1, len(new_spikes_df) + 1)\n",
    "\n",
    "    return new_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "silver-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run specificly do it here\n",
    "def detect_subj(edf='C:\\\\Users\\\\user\\\\PycharmProjects\\\\pythonProject\\\\results\\\\402\\\\402_for_tag.edf'):\n",
    "    raw = mne.io.read_raw_edf(edf)\n",
    "    sampling_rate = int(raw.info['sfreq'])\n",
    "    raw.pick_channels(['RAH1-RAH2'])\n",
    "    # raw.crop(tmin=0, tmax=300)\n",
    "    data = raw.get_data()[0]\n",
    "    detections = detect(data, sampling_rate, threshold_amp, threshold_grad, threshold_env)\n",
    "    # init spikes df and union close spikes\n",
    "    spikes_df = pd.DataFrame(detections, columns=['threshold_type', 'first_index', 'last_index', 'max_index', 'max_amp'])\n",
    "    union_df = union_spikes(spikes_df, sampling_rate)\n",
    "    union_df.to_csv('C:\\\\Users\\\\user\\\\PycharmProjects\\\\pythonProject\\\\results\\\\402\\\\402_for_tag_spikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e00bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run a lot of files- put their path in the list\n",
    "def detect_all():\n",
    "    results_path = 'C:\\\\analysis\\\\{}\\\\thresh_tuning\\\\'\n",
    "    subjects = ['396', '398', '402', '405', '406', '415', '416']\n",
    "\n",
    "    for subj in subjects:\n",
    "        print(subj)\n",
    "        # input path\n",
    "        raw = mne.io.read_raw_edf(f'C:\\\\Lilach\\\\{subj}_for_tag.edf')\n",
    "        sampling_rate = int(raw.info['sfreq'])\n",
    "        # take only most lateral channels (RAH1 or RAH1-RAH2)\n",
    "        for chan in [x for x in raw.ch_names if 'RAH1' in x or 'LAH1' in x]:\n",
    "            print(chan)\n",
    "            chan_data = raw.copy().pick_channels([chan]).get_data()[0]\n",
    "            for thresh in [4, 5, 6, 7, 8, 9, 10]:          \n",
    "                detections = detect(chan_data, sampling_rate, thresh, thresh, thresh)\n",
    "                spikes_df = pd.DataFrame(detections,\n",
    "                                         columns=['threshold_type', 'first_index', 'last_index', 'max_index', 'max_amp'])\n",
    "                union_df = union_spikes(spikes_df, sampling_rate)\n",
    "                union_df.to_csv(f'C:\\\\analysis\\\\{subj}\\\\thresh_tuning\\\\{subj}_{chan}_t{thresh}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb043606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines instead of markers\n",
    "# spike_indexes = np.arange(spikes_list[0][1], spikes_list[0][2] + 1)\n",
    "# plt.plot(data, alpha=0.8)\n",
    "# plt.plot(spike_indexes, data[spike_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dddabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "RAH1\n",
      "LAH1\n",
      "RAH1-RAH2\n",
      "LAH1-LAH2\n",
      "402\n",
      "RAH1\n",
      "LAH1\n",
      "RAH1-RAH2\n",
      "LAH1-LAH2\n",
      "405\n",
      "LAH1\n",
      "LAH1-LAH2\n",
      "406\n",
      "RAH1\n",
      "LAH1\n",
      "RAH1-RAH2\n",
      "LAH1-LAH2\n",
      "415\n",
      "RAH1\n",
      "LAH1\n",
      "RAH1-RAH2\n",
      "LAH1-LAH2\n",
      "416\n",
      "RAH1\n",
      "LAH1\n",
      "RAH1-RAH2\n",
      "LAH1-LAH2\n"
     ]
    }
   ],
   "source": [
    "# detect_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044e56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
